\section{Heurística de búsqueda local}
\subsection{Introducción}
Las heurísticas de búsqueda local son capaces de iterar sobre cualquier solución dada y
mejorarla, buscando soluciones vecinas a la solución inicial.

Para plantear la búsqueda local tenemos que definir sobre qué soluciones vecinas buscará el algoritmo. Es decir, tenemos que definir una relación de vecindad entre el espacio de soluciones del problema. Para que el enfoque no sea complejo, definimos 4 vecindades simples:

\begin{enumerate}
	\item Agregar un nodo a la clique, siempre y cuando siga manteniendo la propiedad de clique.

	\item Eliminar un nodo perteneciente a la clique.

	\item Intercambiar un nodo de la clique por uno que no pertenezca a ella.

	\item Intercambiar un par de nodos de la clique por otro par que no pertenezca a ella.

\end{enumerate}

Ya definidas las vecindades, lo que vamos a hacer en el algoritmo es buscar entre estas soluciones vecinas y quedarnos con la que más nos mejore la frontera, repitiendo este procedimiento hasta que las soluciones encontradas no mejoren.


\subsection{Desarrollo}
Si bien es cierto que la idea de realizar un LocalSearch puede ser aplicada de manera ajena a la solución constructiva golosa que vimos anteriormente, optamos por juntar ambas heurísticas de manera que cada una de las soluciones alternativas que se generen tengan un desarrollo constructivo goloso detrás. De este modo, lo que buscamos es darle a Local la responsabilidad de generar rutas alternativas, con nodos que descartamos en nuestra primera construcción, y a partir de ellas volver a encargarle a nuestro algoritmo constructivo que alcance una solución golosa.

De este modo, si repasamos las vecindades definidas anteriormente, notaremos que tanto agregar como eliminar nodos no son opciones que vayan a servirnos (por lo menos, hasta que apliquemos una nueva heurística sobre estas dos), puesto que Local Search recibirá siempre un algoritmo construido mediante la heurística golosa, donde todos los nodos agregados implican un crecimiento de la frontera y donde no hay ningun nodo externo que agrande la misma.

Por ende, dentro de las vecindades solo nos interesa intercambiar tanto uno como dos nodos de la clique, y a partir de esta nueva clique generar un resultado goloso. No es dificil notar que la vecindad, aún quitándole dos nodos y agregando dos nuevos, es pequeña: para casos con $n$ grande, el hecho de intercambiar solo dos nodos de una solución golosa dificilmente nos lleve a la CMF. Sin embargo, el hecho de correr el algoritmo hasta que no se consigan mejoras puede acercarnos bastante a esta solución, más si consideramos que detrás de la búsqueda local hay una heurística golosa que, para cada iteración, encuentra una solución constructiva aún mejor que la anterior.

Es importante ver que siempre será necesario devolver la solución alternativa luego de aplicarle el algoritmo goloso, puesto que de otro modo podríamos descartar una solución mejor a la actual de manera errónea. Si tomamos nuestra solución inicial, le quitamos dos nodos y le agregamos dos nuevos, si bien es posible que este nuevo grafo tenga una frontera mayor al anterior, también podría ocurrir que se genere una clique de peor solución parcial, pero que al aplicarle el algoritmo goloso nos lleve a una clique con una frontera mayor a la que teníamos. Esto pasaría porque conseguimos armar una clique adyacente a nodos que anteriormente no habíamos considerado, y que finalmente resultaron ser una mejor solución para nuestro problema.

Imaginémoslo con dos montañas, para acercarnos de manera intuitiva. Nosotros estamos parados actualmente en el pico de una montaña, pero al caminar dos pasos para abajo y dos hacia arriba a la derecha, encontramos un camino nuevo. Bien podríamos descartarlo, porque la altura en la que estamos parados actualmente es menor que la anterior, pero al subirlo podríamos acabar en un pico más alto que el anterior. Es por esto que, a la hora de obtener la solución, es mejor tener en cuenta cuál es el pico más alto que puede alcanzar la nueva clique.

Por lo tanto, acabaremos encontrando o bien nuevas soluciones, o bien la misma solución que encontramos en el algoritmo goloso inicial, de forma que siempre acabaremos teniendo un resultado mejor o igual al que se conseguía con la heurística constructiva aislada.

Teniendo esto en cuenta, quedarían definidas de la siguiente manera las vecindades y el resultado obtenido de cada una de ellas. Como las búsquedas de cada tipo de vecindad son diferentes entre sí, vamos a implementar una función que nos encuentre la mejor solución para cada tipo y después vamos a comparar estas soluciones. Esto nos trae el beneficio de que, en caso de agregar nuevas vecindades, no deberemos tocar mucho la implementación.

\subsubsection{Vecindad: Agregar Nodo}

Esta vecindad es la que se aplica en la heurística golosa constructiva. Como ya vimos, la solución que nos va a mejorar más la frontera será agregar el nodo que mantenga la clique y tenga mayor grado.

\begin{algorithm}[H]
	\NoCaptionOfAlgo
	\caption{\algoritmo{localAgregar}{\In{listaAdyacencia}{lista}, \Inout{clique}{solucion}}{}}

    nodosAdyacentes $\leftarrow$ adyacentes(lista, mayor)

    ordenarPorGrado(nodosAdyacentes)

    \For{$i \leftarrow 0$ \KwTo nodosAdyacentes.largo}{
		\If{esAdyacenteATodos(nodosAdyacentes[i], solucion, listaAdyacencia) $\land$ \\ aumentaLaFrontera(nodosAdyacentes[i], solucion, listaAdyacencia)}{
			agregarNodoAClique(solucion, nodosAdyacentes[i])

			break
	    }
    }
    
    solucion $\leftarrow$ algoritmoGoloso(solucion, listaAdyacencia)
\end{algorithm}

\subsubsection{Vecindad: Eliminar Nodo}

Aquí queremos encontrar nodos que al eliminarlos nos aumenten la frontera. Estos nodos van a tener la característica de tener más adyacentes en la clique que afuera, ya que si por ejemplo el nodo $j$ perteneciente a la clique tiene 2 adyacencias por afuera de la misma y esta es de grado 4(por lo que tendrá 3 adyacentes pertenecientes a la clique) al eliminarlo, la frontera perderá los 2 ejes adyacentes a $j$, pero ganará los 3 ejes que llegan de la clique a $j$. Por lo tanto, podemos definir el beneficio de eliminar un nodo de la clique como $2 * (grado de la clique - 1) - cantidad de adyacentes al nodo$.

La implementación es bastante directa, recorremos los nodos de la clique y buscamos el que más nos aporte a la frontera si lo eliminamos.

\begin{algorithm}[H]
	\NoCaptionOfAlgo
	\caption{\algoritmo{localEliminar}{\In{listaAdyacencia}{lista}, \Inout{clique}{solucion}}{}}

    mejora $\leftarrow$ 0

    \For{$i \leftarrow 0$ \KwTo solucion.nodos.largo}{
        mejoraNodo $\leftarrow$ (solucion.nodos.largo - 1) - adyacentesA(lista, solucion.nodos[i]).largo

		\If{mejoraNodo $>$ mejora)}{
			nodoABorrar $\leftarrow$ i

			mejora $\leftarrow$ mejoraNodo
	    }
    }

    \If{mejora $>$ 0)}{
        borrarNodoClique(solucion, solucion.nodos[nodoABorrar])
    }
    
    solucion $\leftarrow$ algoritmoGoloso(solucion, listaAdyacencia)

\end{algorithm}

\subsubsection{Vecindad: Intercambiar Nodo}

Para encontrar el par de nodos(uno interno a la clique y otro externo) que mejoren la clique, lo que vamos a hacer es recorrer los nodos internos y, por cada nodo, buscar en los ejes externos cuanto nos mejora la solución si los intercambiamos.

\begin{algorithm}[H]
	\NoCaptionOfAlgo
	\caption{\algoritmo{localIntercambiar}{\In{listaAdyacencia}{lista}, \Inout{clique}{solucion}}{}}

    mejora $\leftarrow$ 0

    \For{$i \leftarrow 0$ \KwTo solucion.nodos.largo}{
        \For{$j \leftarrow 0$ \KwTo solucion.nodosExternos.largo}{

            mejoraNodo $\leftarrow$ mejoraEnFronteraAlIntercambiar(solucion.nodosExternos[j], solucion.nodos[i], solucion, listaAdyacencia)

            \If{esAdyacenteATodosMenosA(solucion.nodosExternos[j], solucion.nodos[i], solucion, listaAdyacencia) $\land$ \\ mejoraNodo > mejora }{
                nodoABorrar $\leftarrow$ i

                nodoAAgregar $\leftarrow$ j

                mejora $\leftarrow$ mejoraNodo
            }

        }
    }

    \If{mejora $>$ 0)}{
        borrarNodoClique(solucion, nodoABorrar[nodoABorrar])

        agregarNodoClique(solucion, solucion.nodos[nodoAAgregar])
    }
    
    solucion $\leftarrow$ algoritmoGoloso(solucion, listaAdyacencia)

\end{algorithm}

\subsubsection{Vecindad: Intercambiar par de nodos}
La idea de intercambiar un par de nodos es similar a la explicada a la hora de intercambiar un único nodo, con la diferencia que a la hora de generar la solución final (es decir, a la hora de aplicarle el algoritmo goloso) deberá primero haberse hecho el intercambio de ambos nodos. Por lo tanto, la idea sería:
\begin{itemize}
	\item Sacar dos nodos
	\item Meter dos nodos
	\item Algoritmo goloso sobre la nueva clique
\end{itemize}

\subsubsection{Algoritmo final}
Finalmente, considerando estas cuatro vecindades, acabaremos teniendo un algoritmo general de este estilo:

\begin{algorithm}[H]
 \NoCaptionOfAlgo
 \caption{\algoritmo{heuristicaDeBusquedaLocal}{\In{listaAdyacencia}{lista}, \Inout{clique}{solucion}}{}}

    \While {esMejor}{
        esMejor $\leftarrow$ falso

        posibleMejorSolucion $\leftarrow$ buscarMejorSolucionVecina(lista, solucion)

        \If{posibleMejorSolucion.fronter > solucion.frontera)}{
            esMejor $\leftarrow$ verdadero

            solucion $\leftarrow$ posibleMejorSolucion
        }
    }

\end{algorithm}

Donde buscarMejorSolucionVecina corre las cuatro vecindades y se fija cual es la mejor.

\subsection{Complejidad Temporal}
Para analizar la complejidad temporal de este ejercicio, debemos analizar la complejidad de cada una de los algoritmos que corremos para realizar la búsqueda en sus vecindades. Por lo tanto, tendremos las siguientes complejidades:

\begin{center}
	\textbf{Agregar nodo}
\end{center}
Este algoritmo recorre los nodos que no pertenecen a la clique (que son, como máximo, $n$) y, para cada uno de ellos, chequea si es o no adyacente a los nodos de la clique, y si agregarlo aumenta la frontera. Por lo tanto, para $n$ nodos, se fijará si el vértice es adyacente a la clique y realizará el cálculo correspondiente. Como vimos anteriormente, el algoritmo \textbf{esAdyacenteATodos} tiene una cota temporal de $O(n)$, mientras que el cálculo correspondiente a la frontera se realiza en $O(1)$. Por ende, acabamos teniendo n veces que realizar una operación de complejidad $O(n)$ (es decir, complejidad de $O(n^2)$). A esta solución obtenida le aplicamos finalmente el \textbf{Algoritmo Goloso}, cuya complejidad vimos que es $O( n*log(n) + n*|cliqueMax| + m)$, donde $O(n*log(n))$, $O(n*|cliqueMax|)$ y $O(m)$ se pueden acotar por $O(n^2)$, por lo que terminaríamos teniendo $O(n^2 + n^2)$. Por lo tanto, acotando por última vez esta complejidad, concluímos que la complejidad de Agregar Nodo es $O(n^2)$.

\begin{center}
	\textbf{Eliminar nodo}
\end{center}
Este algoritmo recorre los nodos de la clique (máximo $n$ nodos) y para cada uno de ellos se fija si, al quitar este nodo, la frontera de la clique mejora. Como nuevamente, lo único que tenemos que hacer es realizar el cálculo de la frontera en $O(1)$, la complejidad de este ciclo será $O(n)$. Finalmente, como vimos, le corremos el \textbf{Algoritmo Goloso} a la solución, lo cual tiene una complejidad $O( n*log(n) + n*|cliqueMax| + m)$ pero que, como vimos, se puede acotar por $O(n^2)$. Por ende, como sabemos que esta complejidad se sumará con la de Agregar Nodo, y el resto de la complejidad de Eliminar Nodo es despreciable frente al Algoritmo Goloso, definimos que la cota temporal de Eliminar Nodo es $O(n^2)$.

\begin{center}
	\textbf{Intercambiar nodos}
\end{center}
Si bien tenemos dos tipos de intercambios, de la manera en que definimos cada uno de ellos podemos asegurarnos que la cota temporal de intercambiar un solo nodo es menor a la de intercambiar dos. Por lo tanto, como a la larga sus complejidades se sumarán y una de ellas será despreciable, vamos a centrarnos en la complejidad de intercambiar dos nodos internos por dos externos.

Este algoritmo tomará la clique original deberá sacar dos nodos de ella (donde la cantidad máxima es $n$) e ingresar dos nuevos. Es facil ver que extraer cada par de nodos es igual a separarlos y realizar la siguiente operación:

\textbf{Para cada nodo $i$ $\in$ clique, para cada nodo $j$ $\in$ clique, j $\neq$ i, extraer j e i.}

Esto nos deja con una complejidad de $O(n^2)$, a la cual se le debe sumar la de agregar los nodos externos de la clique. De nuevo, tendremos la misma operación, pero esta vez por afuera de la clique, es decir:

\textbf{Para cada nodo $i$ fuera de clique, para cada nodo $j$ fuera de  clique, j $\neq$ i, agregar j e i.}

Por lo tanto, como debemos tanto agregar como sacar nodos, acabaremos teniendo $O(n^2 * n^2)$, lo cual acaba siendo $O(n^4)$, el hecho de tan solo recorrer todas las cliques que podríamos generar. A su vez, para cada una de estas posibles cliques debemos asegurarnos si los dos nodos agregados son adyacentes a todos los demas, y como vimos \textbf{esAdyacenteATodos} tiene una cota temporal de $O(n)$, y al realizarlo dos veces (una por cada nodo del par) tendremos $O(2n)$ $\subseteq$ $O(n)$.	
\bigskip

\begin{center}
\textbf{PLUS REENTREGA}

Además, le realizamos greedy a cada uno, es decir que si teniamos $O(n^5)$, ahora tendremos $O(n^5 * (greedy))$, que vimos que es $O(n*log + n*|cliqueMax| + m)$, y se puede acotar por $O(n^2)$, entonces nos da $O(n^7)$. Finalmente, cuando le multipliquemos el ultimo n tendremos $O(n^8)$, siendo esta la verdadera complejidad

\textbf{PLUS REENTREGA}

\bigskip
\end{center}

Por lo demás, son cálculos realizables en $O(1)$ que no afectan nuestra complejidad, por lo que acabaremos teniendo, para cada posible clique, una complejidad de $O(n)$, lo cual acaba siendo al considerar todas las complejidades $O(n^5)$.
\bigskip

Así, alcanzamos las complejidades de cada una de nuestras vecindades. Por lo tanto, la complejidad de buscar la mejor solución vecina será $O(n^2 + n^2 + n^5)$, que por propiedades de O grande se acota finalmente con $O(n^5)$. Puesto que el algoritmo general es, simplemente, tomar una clique y correrle el algoritmo hasta que no mejore, el mismo correrá un máximo de $n$ veces (o bien agrega $n$ nodos, o bien los saca). Por lo tanto, al considerar el peor caso, habremos corrido $n$ veces un algoritmo de costo $O(n^5)$, dejándonos con una complejidad temporal final de $O(n^6)$

